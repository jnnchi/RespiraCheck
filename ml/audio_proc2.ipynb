{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing.audio_processor import AudioProcessor\n",
    "from data_processing.spectrogram_processor import SpectrogramProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing.audio_processor import AudioProcessor\n",
    "import pandas as pd\n",
    "from IPython.display import Audio\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- Example for running the reduce_noise function ------------- \n",
    "metadata_df = pd.DataFrame({\n",
    "    \"file_name\": [\"sample_audio.wav\"],\n",
    "    \"duration\": [5.0]\n",
    "})\n",
    "input_folder = 'data/cough_data/original_data'\n",
    "\n",
    "audio_processor = AudioProcessor(\n",
    "    input_folder=input_folder,\n",
    "    target_sample_rate=32000,  \n",
    "    target_duration=15.0,       \n",
    "    metadata_df=metadata_df\n",
    ")\n",
    "#C:\\Users\\houma\\RespiraCheck\\ml\\data\\cough_data\\original_data\\ff2493d0-17da-4e51-b794-d10876b7048b.mp3\n",
    "print(\"Processed Audio (Normalized for playback):\")\n",
    "audio = AudioSegment.from_file(\"data/cough_data/original_data/ff2493d0-17da-4e51-b794-d10876b7048b.mp3\")\n",
    "x = audio_processor.reduce_noise(audio)\n",
    "display(Audio(x, rate=audio.frame_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #  ------------------- example for running the remove_no_cough function -------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Define the input folder and sample input for testing\n",
    "input_folder = 'data/cough_data/original_data'\n",
    "sample_input_for_testing = 'data/cough_data/original_data/fee168b1-58b4-45ba-b2aa-f30d13e4af2f.mp3'\n",
    "\n",
    "metadata_df = pd.DataFrame({\n",
    "    \"file_name\": [\"sample_audio.wav\"],\n",
    "    \"duration\": [5.0]\n",
    "})\n",
    "\n",
    "audio_processor = AudioProcessor(\n",
    "    input_folder=input_folder,\n",
    "    target_sample_rate=32000,  \n",
    "    target_duration=15.0,       \n",
    "    metadata_df=metadata_df\n",
    ")\n",
    "\n",
    "def convert_to_wav_pydub(file_path):\n",
    "    if not file_path.lower().endswith('.wav'):\n",
    "        wav_file_path = os.path.splitext(file_path)[0] + '.wav'\n",
    "        if file_path.lower().endswith('.mp3'):\n",
    "            sound = AudioSegment.from_mp3(file_path)\n",
    "        elif file_path.lower().endswith('.flac'):\n",
    "            sound = AudioSegment.from_file(file_path, format=\"flac\")\n",
    "        elif file_path.lower().endswith('.ogg'):\n",
    "            sound = AudioSegment.from_file(file_path, format=\"ogg\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file format: {file_path}\")\n",
    "        \n",
    "        sound.export(wav_file_path, format=\"wav\")\n",
    "        \n",
    "        return wav_file_path\n",
    "    else:\n",
    "        return file_path\n",
    "\n",
    "sample_input_for_testing = convert_to_wav_pydub(sample_input_for_testing)\n",
    " \n",
    "initial_size = sum(os.path.getsize(os.path.join(input_folder, f)) for f in os.listdir(input_folder))\n",
    "\n",
    "# Process the audio file\n",
    "audio_processor.remove_no_cough(sample_input_for_testing)\n",
    "# Find final folder size\n",
    "final_size = sum(os.path.getsize(os.path.join(input_folder, f)) for f in os.listdir(input_folder))\n",
    "if final_size < initial_size:\n",
    "    print(\"File sucessfully removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Example using the fbank feature extraction function ---------\n",
    "def fbank(audio_path, samplerate=16000, winlen=0.025, winstep=0.01,\n",
    "          nfilt=40, nfft=512, lowfreq=0, highfreq=None, preemph=0.97, \n",
    "          wintype='hamming', grayscale=False, save_image=False, image_path=\"fbank_image.png\"):\n",
    "        \"\"\"Compute Mel-filterbank energy features and optionally convert to a grayscale image.\n",
    "        \n",
    "        :param audio_path: Path to the audio file.\n",
    "        :param samplerate: Sample rate of the signal.\n",
    "        :param winlen: Window length in seconds.\n",
    "        :param winstep: Step size between windows in seconds.\n",
    "        :param nfilt: Number of Mel filters.\n",
    "        :param nfft: FFT size.\n",
    "        :param lowfreq: Lowest frequency in Mel filters.\n",
    "        :param highfreq: Highest frequency in Mel filters.\n",
    "        :param preemph: Pre-emphasis factor.\n",
    "        :param wintype: Window function type.\n",
    "        :param grayscale: Whether to convert the filterbank to a grayscale image.\n",
    "        :param save_image: Whether to save the grayscale image.\n",
    "        :param image_path: File path to save the image.\n",
    "        :return: Filterbank features (2D numpy array).\n",
    "            \"\"\"\n",
    "        signal, samplerate = librosa.load(audio_path, sr=samplerate)\n",
    "        \n",
    "        highfreq = highfreq or samplerate / 2\n",
    "        \n",
    "        signal = np.append(signal[0], signal[1:] - preemph * signal[:-1])\n",
    "        \n",
    "        frame_length = int(winlen * samplerate)\n",
    "        frame_step = int(winstep * samplerate)\n",
    "        frames = librosa.util.frame(signal, frame_length=frame_length, hop_length=frame_step).T\n",
    "        \n",
    "        if wintype == 'hamming':\n",
    "            window = np.hamming(frame_length)\n",
    "        elif wintype == 'hann':\n",
    "            window = np.hanning(frame_length)\n",
    "        else:\n",
    "            window = np.ones(frame_length)\n",
    "        frames = frames.copy()\n",
    "\n",
    "        frames *= window\n",
    "        \n",
    "        mag_frames = np.abs(np.fft.rfft(frames, n=nfft))\n",
    "        pow_frames = (1.0 / nfft) * (mag_frames ** 2)\n",
    "        \n",
    "        mel_filters = librosa.filters.mel(sr=samplerate, n_fft=nfft, n_mels=nfilt, fmin=lowfreq, fmax=highfreq)\n",
    "        fbank_features = np.dot(pow_frames, mel_filters.T)\n",
    "        # linear scaling\n",
    "        #fbank_features = np.where(fbank_features == 0, np.finfo(float).eps, fbank_features)\n",
    "\n",
    "        # log scaling - makes differences more apparent\n",
    "        fbank_features = librosa.power_to_db(fbank_features, ref=np.max)\n",
    "\n",
    "        if grayscale or save_image:\n",
    "            plt.figure(figsize=(4, 4))\n",
    "            plt.imshow(fbank_features.T, cmap='gray', origin='lower', aspect='auto')\n",
    "            plt.axis('off')\n",
    "            if save_image:\n",
    "                plt.savefig(image_path, bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()\n",
    "        \n",
    "        return fbank_features\n",
    "fbank_features =fbank(\"data/cough_data/original_data/0a1c8e24-81d7-404e-8a85-b3fd3999ecb5.mp3\", grayscale=True, save_image=True)\n",
    "print(fbank_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
