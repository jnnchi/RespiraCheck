{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYscyCg6b7rZ"
      },
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import collections\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import random_split, DataLoader, TensorDataset, WeightedRandomSampler\n",
        "from torchvision import transforms\n",
        "import io\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0AUU9kYcUAv",
        "outputId": "ad66fc9b-afa9-468a-f0f7-0d9d212d82f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    \"\"\"A convolutional neural network model based on EfficientNet for spectrogram processing.\"\"\"\n",
        "\n",
        "    def __init__(self, dropout: float = 0.0):\n",
        "        \"\"\"Initializes the CNNModel using EfficientNet-B0 with an optional dropout layer.\n",
        "\n",
        "        Args:\n",
        "            dropout (float): Dropout probability before the final classification layer.\n",
        "        \"\"\"\n",
        "        super(CNNModel, self).__init__()\n",
        "\n",
        "        # Load EfficientNet-B0 with pre-trained weights\n",
        "        self.efficientnet = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
        "\n",
        "        # Get the number of features from the last layer of EfficientNet\n",
        "        num_features = self.efficientnet.classifier[1].in_features\n",
        "\n",
        "        # Replace the classifier with a new sequence including Dropout and FC layer\n",
        "        self.efficientnet.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=dropout),  # Dropout before classification layer\n",
        "            nn.Linear(num_features, 1)  # Binary classification output\n",
        "        )\n",
        "\n",
        "        # Initialize the new FC layer weights\n",
        "        nn.init.normal_(self.efficientnet.classifier[1].weight, mean=0.0, std=0.01)\n",
        "        nn.init.zeros_(self.efficientnet.classifier[1].bias)\n",
        "\n",
        "    def forward(self, spectrogram: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Defines the forward pass for EfficientNet with dropout.\n",
        "\n",
        "        Args:\n",
        "            spectrogram (torch.Tensor): Input tensor representing the spectrogram.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The model's output (logit for binary classification).\n",
        "        \"\"\"\n",
        "        return self.efficientnet(spectrogram)\n"
      ],
      "metadata": {
        "id": "tbLR_B94cdPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelHandler:\n",
        "    \"\"\"Handles the model training, evaluation, and inference pipeline.\n",
        "\n",
        "    Attributes:\n",
        "        device (torch.device): The device on which the model is executed (e.g., 'cpu' or 'cuda').\n",
        "        model_path: Path to where .pth models should be saved.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 model,\n",
        "                 model_path: str,\n",
        "                 optimizer: torch.optim.Optimizer,\n",
        "                 loss_function: nn.Module,\n",
        "                 steps_per_decay = 5,\n",
        "                 lr_decay = 0.1):\n",
        "        \"\"\"Initializes the ModelHandler.\n",
        "\n",
        "        Args:\n",
        "            model_path (str | None): Path to the pre-trained model file (if available).\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.model_path = model_path\n",
        "        self.optimizer = optimizer\n",
        "        self.lr_scheduler = opt.lr_scheduler.StepLR(self.optimizer, step_size=steps_per_decay, gamma=lr_decay)\n",
        "        self.loss_function = loss_function\n",
        "\n",
        "    def train_step(self, dataloader):\n",
        "        \"\"\"Trains the model for a single epoch.\n",
        "\n",
        "        Args:\n",
        "            dataloader (torch.utils.data.DataLoader): DataLoader for the training dataset.\n",
        "        \"\"\"\n",
        "        self.model.train()\n",
        "        avg_loss, acc = 0, 0\n",
        "        for in_tensor, labels in dataloader:\n",
        "            in_tensor, labels = in_tensor.to(self.device), labels.to(self.device)\n",
        "            labels = labels.float().unsqueeze(1)  # Ensure correct shape for BCE loss\n",
        "\n",
        "            logits = self.model(in_tensor) # Feed input into model\n",
        "\n",
        "            loss = self.loss_function(logits, labels)  # Calculate loss\n",
        "            avg_loss += loss.item()  # Add to cumulative loss\n",
        "\n",
        "            # Gradient descent\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            # Calculate batch accuracy and add it to cumulative accuracy\n",
        "            prediction_classes = torch.round(torch.sigmoid(logits))\n",
        "            batch_acc = torch.mean((prediction_classes == labels).float()).item()\n",
        "            acc += batch_acc\n",
        "\n",
        "        avg_loss /= len(dataloader)  # Calculate avg loss for epoch from cumulative loss\n",
        "        acc /= len(dataloader)  # Calculate avg accuracy for epoch from cumulative accuracy\n",
        "        train_results = {\"avg_loss_per_batch\": avg_loss, \"avg_acc_per_batch\": acc * 100}\n",
        "        return train_results\n",
        "\n",
        "    def val_step(self, dataloader):\n",
        "        \"\"\"Evaluates the model on the validation dataset.\n",
        "\n",
        "        Args:\n",
        "            dataloader (torch.utils.data.DataLoader): DataLoader for the validation dataset.\n",
        "        \"\"\"\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.inference_mode():\n",
        "            avg_loss, acc = 0, 0\n",
        "            for in_tensor, labels in dataloader:\n",
        "                in_tensor, labels = in_tensor.to(self.device), labels.to(self.device)\n",
        "                labels = labels.float().unsqueeze(1)  # Ensure correct shape for BCE loss\n",
        "\n",
        "                logits = self.model(in_tensor)  # Feed input into model\n",
        "\n",
        "                loss = self.loss_function(logits, labels)  # Calculate loss\n",
        "                avg_loss += loss.item()  # Add to cumulative loss\n",
        "\n",
        "                # Calculate batch accuracy and add it to cumulative accuracy\n",
        "                prediction_classes = torch.round(torch.sigmoid(logits))\n",
        "                batch_acc = torch.mean((prediction_classes == labels).float()).item()\n",
        "                acc += batch_acc\n",
        "\n",
        "            avg_loss /= len(dataloader)  # Calculate avg loss for each epoch from cumulative loss\n",
        "            acc /= len(dataloader)  # Calculate avg accuracy for each epoch from cumulative accuracy\n",
        "            valid_results = {\"avg_loss_per_batch\": avg_loss, \"avg_acc_per_batch\": acc * 100}\n",
        "            return valid_results\n",
        "\n",
        "    def train(self, train_loader, epochs: int, model_name: str):\n",
        "        \"\"\"Trains the model\n",
        "\n",
        "        Args:\n",
        "            train_loader: DataLoader for the training datasets\n",
        "            epochs (int): Number of training epochs.\n",
        "            model_name (str): Name to save the trained model.\n",
        "        \"\"\"\n",
        "        self.model.to(self.device)\n",
        "        training_results = {\"epoch\": [], \"loss\": [], \"accuracy\": []}\n",
        "        validation_results = {\"epoch\": [], \"loss\": [], \"accuracy\": []}\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            # Train the model\n",
        "            training_data = self.train_step(train_loader)\n",
        "            training_results[\"epoch\"].append(epoch)\n",
        "            training_results[\"loss\"].append(training_data[\"avg_loss_per_batch\"])\n",
        "            training_results[\"accuracy\"].append(training_data[\"avg_acc_per_batch\"])\n",
        "\n",
        "            # Check the validation loss after training\n",
        "            validation_data = self.val_step(val_loader)\n",
        "            validation_results[\"epoch\"].append(epoch)\n",
        "            validation_results[\"loss\"].append(validation_data[\"avg_loss_per_batch\"])\n",
        "            validation_results[\"accuracy\"].append(validation_data[\"avg_acc_per_batch\"])\n",
        "\n",
        "            # Adjust learning rate if necessary\n",
        "            if self.lr_scheduler:\n",
        "                self.lr_scheduler.step()\n",
        "\n",
        "            if epoch % 1 == 0:\n",
        "                print(f\"{epoch}:\")\n",
        "                print(f\"LR: {self.optimizer.param_groups[0]['lr']}\")\n",
        "                print(f\"Loss - {training_data['avg_loss_per_batch']:.5f} | Accuracy - {training_data['avg_acc_per_batch']:.2f}%\")\n",
        "                print(f\"VLoss - {validation_data['avg_loss_per_batch']:.5f} | VAccuracy - {validation_data['avg_acc_per_batch']:.2f}%\\n\")\n",
        "\n",
        "        self.save_model(model_state_dict=self.model.state_dict(), model_name=model_name)\n",
        "        return training_results, validation_results\n",
        "\n",
        "\n",
        "    def validate(self, val_loader, hyperparams: dict, save_best: bool = True) -> tuple[float, float]:\n",
        "        \"\"\"Validates the model on the validation dataset.\n",
        "\n",
        "        Args:\n",
        "            val_loader: DataLoader for the validation dataset.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (validation accuracy, validation loss)\n",
        "        \"\"\"\n",
        "\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "        val_losses_epoch, batch_sizes, accs = [], [], []\n",
        "        best_acc = -1\n",
        "        best_model_state = None  # Track the best model weights\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X_val, y_val in val_loader:\n",
        "                X_val = X_val.to(self.device)\n",
        "                y_val = y_val.to(self.device).float().unsqueeze(1)\n",
        "\n",
        "                y_prediction_val = self.model(X_val)  # forward pass\n",
        "                loss = self.loss_function(y_prediction_val, y_val)\n",
        "                val_losses_epoch.append(loss.item())\n",
        "\n",
        "                # Compute accuracy\n",
        "                y_prediction_val = torch.sigmoid(y_prediction_val)  # Convert logits to probabilities\n",
        "                prediction_classes = (y_prediction_val > 0.5).float()  # Convert to binary 0/1\n",
        "\n",
        "                acc = torch.mean((prediction_classes == y_val).float()).item()\n",
        "                accs.append(acc)\n",
        "                batch_sizes.append(X_val.shape[0])\n",
        "\n",
        "        # Compute final validation loss and accuracy\n",
        "        val_loss = np.mean(val_losses_epoch)\n",
        "        val_acc = np.average(accs, weights=batch_sizes)  # Weighted average accuracy\n",
        "\n",
        "        print(f'Validation accuracy: {val_acc*100:.2f}% | Validation loss: {val_loss:.4f}')\n",
        "\n",
        "        if save_best and val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_model_state = self.model.state_dict()\n",
        "\n",
        "            # Create model filename using hyperparameters\n",
        "            hyperparam_str = \"_\".join(f\"{key}:{value}\" for key, value in hyperparams.items())\n",
        "            model_filename = f\"model_{hyperparam_str}_{time.time()}.pth\"\n",
        "\n",
        "            # Save the best model\n",
        "            save_path = os.path.join(self.model_path, model_filename)\n",
        "            torch.save(best_model_state, save_path)\n",
        "            print(f\"Best model saved at: {save_path}\")\n",
        "        return val_acc, val_loss\n",
        "\n",
        "\n",
        "    def evaluate(self, test_loader) -> float:\n",
        "        \"\"\"Evaluates the model on the test dataset.\n",
        "\n",
        "        Args:\n",
        "            test_loader: DataLoader for the test dataset.\n",
        "        \"\"\"\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "        batch_sizes, accs = [], []\n",
        "        with torch.no_grad():\n",
        "            for X_test, y_test, in test_loader:\n",
        "                X_test = X_test.to(self.device)\n",
        "                y_test = y_test.to(self.device)\n",
        "\n",
        "                prediction = self.model(X_test)\n",
        "                batch_sizes.append(X_test.shape[0])\n",
        "\n",
        "                prediction = torch.sigmoid(prediction)\n",
        "                prediction_classes = (prediction > 0.5).float() # This converts to binary classes 0 and 1\n",
        "\n",
        "                acc = torch.mean((prediction_classes == y_test).float()).item()\n",
        "                accs.append(acc)\n",
        "\n",
        "        # Return average accuracy\n",
        "        return 0.0 if not accs else np.average(accs, weights=batch_sizes)\n",
        "\n",
        "\n",
        "    def predict(self, spectrogram: torch.Tensor, model_name: str) -> int:\n",
        "        \"\"\"Performs inference on a single spectrogram.\n",
        "\n",
        "        Args:\n",
        "            spectrogram (torch.Tensor): Input spectrogram for inference.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The predicted output from the model.\n",
        "        \"\"\"\n",
        "        self.load_model(self.model_path +f\"/{model_name}\")\n",
        "        spectrogram = spectrogram.unsqueeze(0).to(self.device)\n",
        "\n",
        "        with torch.no_grad:\n",
        "            logits = self.model(spectrogram)\n",
        "\n",
        "            probability = torch.sigmoid(logits)\n",
        "\n",
        "            prediction = (probability > 0.5).float() # Turn probability into binary classificaiton\n",
        "\n",
        "        return prediction.item()\n",
        "\n",
        "\n",
        "    def save_model(self, model_state_dict: collections.OrderedDict, model_name: str | None) -> None:\n",
        "        \"\"\"Saves the model to the specified file path.\n",
        "\n",
        "        Args:\n",
        "            path (str): Path to save the model file.\n",
        "        \"\"\"\n",
        "        path = self.model_path + \"/\" + model_name\n",
        "        torch.save(model_state_dict, path)\n",
        "\n",
        "\n",
        "    def load_model(self, path: str) -> None:\n",
        "        \"\"\"Loads a model from the specified file path.\n",
        "\n",
        "        Args:\n",
        "            path (str): Path to the model file.\n",
        "        \"\"\"\n",
        "        self.model.load_state_dict(torch.load(path))\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()"
      ],
      "metadata": {
        "id": "9ydySeiGchks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataPipeline:\n",
        "    \"\"\"Processes datasets, including loading, splitting, and preparing for inference.\n",
        "\n",
        "    This class provides methods for loading datasets, processing them for training,\n",
        "    and preparing single instances for inference.\n",
        "\n",
        "    Attributes:\n",
        "        test_size (float): Proportion of the dataset to include in the test split.\n",
        "        val_size (float): Proportion of the dataset to include for validation.\n",
        "        audio_processor: AudioProcessor instance for handling audio processing.\n",
        "        image_processor: ImageProcessor instance for handling spectrogram or extracted features processing.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, test_size: float, val_size: float):\n",
        "        \"\"\"Initializes the DatasetProcessor.\n",
        "\n",
        "        Args:\n",
        "            data_path (str): Path to the dataset file.\n",
        "            test_size (float): Proportion of the dataset to include in the test split.\n",
        "            audio_processor (AudioProcessor): Instance for handling audio processing.\n",
        "            image_processor (ImageProcessor): Instance for handling spectrogram processing.\n",
        "        \"\"\"\n",
        "        self.test_size = test_size\n",
        "        self.val_size = val_size\n",
        "\n",
        "    def load_dataset(self) -> TensorDataset:\n",
        "        \"\"\"Loads the dataset from the specified file path into a DataFrame.\"\"\"\n",
        "        tensors = []\n",
        "        labels = []\n",
        "\n",
        "        for label_folder, label_value in zip([\"positive\", \"negative\"], [1, 0]):\n",
        "            spectrogram_folder = '/content/drive/MyDrive/RespiraCheck/Cough Data/spectrograms'\n",
        "            output_dir = os.path.join(spectrogram_folder, label_folder)\n",
        "\n",
        "            for image_name in tqdm(os.listdir(output_dir)):\n",
        "                image_path = os.path.join(output_dir, image_name)\n",
        "                image_tensor = self.image_to_tensor(image_path)\n",
        "\n",
        "                tensors.append(image_tensor)\n",
        "                labels.append(label_value)\n",
        "\n",
        "        # Tensor of all features (N x D) - N is number of samples (377), D is feature dimension (3,224,224)\n",
        "        X = torch.stack(tensors)\n",
        "        # Tensor of all labels (N x 1) - 377x1\n",
        "        y = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "        return TensorDataset(X, y)\n",
        "\n",
        "\n",
        "    def image_to_tensor(self, image_path: str) -> torch.Tensor:\n",
        "        \"\"\"Converts a spectrogram image to a PyTorch tensor.\n",
        "\n",
        "        Args:\n",
        "            image_path (str): Path to the spectrogram image file.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The PyTorch tensor representation of the image.\n",
        "        \"\"\"\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),  # Resize to ResNet18 input size\n",
        "            transforms.ToTensor(),  # Convert image to tensor\n",
        "        ])\n",
        "\n",
        "        image = Image.open(image_path).convert(\"RGB\") # Convert from RGBA to RGB\n",
        "        tensor_image = transform(image)\n",
        "\n",
        "        return tensor_image  # shape will be 3, 224, 224\n",
        "\n",
        "    def create_dataloaders(self, batch_size, dataset_path = None, upsample = True) -> tuple[DataLoader, DataLoader, DataLoader]:\n",
        "        \"\"\"Splits the dataset into training and test sets.\n",
        "\n",
        "        Args:\n",
        "            batch_size (int): The batch size for the DataLoader.\n",
        "            dataset_path (str | None): Path to the TensorDataset file.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (train_df, test_df) - The training and testing DataFrames.\n",
        "        \"\"\"\n",
        "        if dataset_path:\n",
        "            print(f\"Loading dataset from {dataset_path}\")\n",
        "            dataset = torch.load(dataset_path, weights_only=False)\n",
        "        else:\n",
        "            print(\"Processing and loading dataset\")\n",
        "            dataset = self.load_dataset()\n",
        "\n",
        "        # Calculate sizes\n",
        "        test_size = round(self.test_size * len(dataset))\n",
        "        val_size = round(self.val_size * len(dataset))\n",
        "        train_size = round(len(dataset) - test_size - val_size)  # Remaining for training\n",
        "\n",
        "        # Perform split\n",
        "        train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "        # Upsample positive class\n",
        "        if upsample:\n",
        "            print(\"Upsampling data\")\n",
        "            labels = [label.item() for _, label in train_dataset]\n",
        "            train_counts = {}\n",
        "            for label in labels:\n",
        "                train_counts[label] = train_counts.get(label, 0) + 1\n",
        "            # print(train_counts)\n",
        "\n",
        "            weights = torch.where(torch.tensor(labels) == 0, 1 / train_counts[0], 1 / train_counts[1])\n",
        "            # print(labels[:5], weights[:5])\n",
        "\n",
        "            wr_sampler = WeightedRandomSampler(weights, int(len(train_dataset) * 1.5))\n",
        "\n",
        "            train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=wr_sampler)\n",
        "\n",
        "        else:\n",
        "            print(\"No upsampling\")\n",
        "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        # Create DataLoaders\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        # Count labels in train_loader\n",
        "        train_counts = {}\n",
        "        for _, labels in train_loader:\n",
        "            for label in labels:\n",
        "                train_counts[label.item()] = train_counts.get(label.item(), 0) + 1\n",
        "\n",
        "        # print(train_counts)\n",
        "\n",
        "        # Reduce memory footprint\n",
        "        dataset, train_dataset, val_dataset, test_dataset = None, None, None, None\n",
        "\n",
        "        return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "TtrsfN7QcjgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install noisereduce"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-G52vhfgVU9",
        "outputId": "5cc855c2-c74a-4d77-ec8d-9a54156276da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: noisereduce in /usr/local/lib/python3.11/dist-packages (3.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from noisereduce) (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from noisereduce) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from noisereduce) (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from noisereduce) (4.67.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from noisereduce) (1.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->noisereduce) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as opt\n",
        "\n",
        "# Static hyperparameters\n",
        "EPOCHS = 20\n",
        "\n",
        "# Learning rate scheduler\n",
        "STEPS_PER_LR_DECAY = 20\n",
        "LR_DECAY = 0.5\n",
        "\n",
        "# Model parameters\n",
        "DROPOUT = 0.5\n",
        "\n",
        "# Training\n",
        "LOSS_FN = nn.BCEWithLogitsLoss()\n",
        "\n"
      ],
      "metadata": {
        "id": "k3JgY0lnclQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNNModel(DROPOUT)"
      ],
      "metadata": {
        "id": "rgLkS_upcm6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datapipeline = DataPipeline(test_size=0.15, val_size=0.15)\n",
        "train_loader, val_loader, test_loader = datapipeline.create_dataloaders(batch_size=8)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItAMI1yPcohx",
        "outputId": "dc037849-90f4-4f38-a4de-c546ab4e2378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing and loading dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 842/842 [00:24<00:00, 33.93it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2986/2986 [01:16<00:00, 38.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upsampling data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as opt\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# Define fixed hyperparameters\n",
        "batch_size = 16  # Choose a single batch size\n",
        "learning_rate = 0.001  # Set the learning rate\n",
        "\n",
        "print(f\"\\nðŸš€ Training with batch size: {batch_size}, learning rate: {learning_rate}\")\n",
        "\n",
        "# Initialize model\n",
        "cnn_model = CNNModel()\n",
        "\n",
        "# Choose optimizer (AdamW is better than Adam for weight decay)\n",
        "optimizer = opt.AdamW(params=cnn_model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "\n",
        "# Learning rate scheduler (Reduce LR if validation loss doesnâ€™t improve)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=True)\n",
        "\n",
        "# Create ModelHandler\n",
        "model_handler = ModelHandler(model=cnn_model,\n",
        "                             model_path=\"/content/drive/MyDrive/RespiraCheck/Cough Data\",\n",
        "                             optimizer=optimizer,\n",
        "                             loss_function=LOSS_FN,\n",
        "                             steps_per_decay=STEPS_PER_LR_DECAY,\n",
        "                             lr_decay=LR_DECAY)\n",
        "\n",
        "# Load dataset with the chosen batch size\n",
        "datapipeline = DataPipeline(test_size=0.15, val_size=0.15)\n",
        "train_loader, val_loader, test_loader = datapipeline.create_dataloaders(batch_size=batch_size)\n",
        "\n",
        "# Early stopping setup\n",
        "patience = 5\n",
        "best_val_loss = float(\"inf\")\n",
        "epochs_since_improve = 0\n",
        "best_model = None\n",
        "best_acc = 0.0\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\nðŸ”„ Epoch {epoch+1}/{EPOCHS}\")\n",
        "\n",
        "    # Train\n",
        "    training_results, validation_results = model_handler.train(train_loader=train_loader, epochs=1, model_name=\"CNN_EfficientNet\")\n",
        "\n",
        "    # Validate\n",
        "    val_acc, val_loss = model_handler.validate(val_loader, {\"batch_size\": batch_size, \"lr\": learning_rate})\n",
        "\n",
        "    # Scheduler step\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Early stopping check\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        epochs_since_improve = 0\n",
        "    else:\n",
        "        epochs_since_improve += 1\n",
        "        if epochs_since_improve >= patience:\n",
        "            print(\"â¹ï¸ Early stopping triggered!\")\n",
        "            break  # Stop training\n",
        "\n",
        "    # Save the best model based on accuracy\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        best_model = model_handler\n",
        "\n",
        "    print(f\"âœ… Validation accuracy: {val_acc*100:.2f}% | Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "# Final Testing\n",
        "if best_model:\n",
        "    test_acc = best_model.evaluate(test_loader)\n",
        "    print(f\"\\nðŸŽ¯ Test accuracy: {test_acc*100:.2f}% ðŸš€ Best model saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXMzHuqedyuC",
        "outputId": "085318d8-a2b5-473f-9aa5-89b7edc196c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸš€ Training with batch size: 16, learning rate: 0.001\n",
            "Processing and loading dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 842/842 [00:20<00:00, 41.34it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2986/2986 [00:50<00:00, 58.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upsampling data\n",
            "\n",
            "ðŸ”„ Epoch 1/20\n",
            "0:\n",
            "LR: 0.001\n",
            "Loss - 0.69161 | Accuracy - 55.26%\n",
            "VLoss - 0.72579 | VAccuracy - 36.01%\n",
            "\n",
            "Validation accuracy: 36.06% | Validation loss: 0.7258\n",
            "Best model saved at: /content/drive/MyDrive/RespiraCheck/Cough Data/model_batch_size:16_lr:0.001_1740873099.7350264.pth\n",
            "âœ… Validation accuracy: 36.06% | Validation loss: 0.7258\n",
            "\n",
            "ðŸ”„ Epoch 2/20\n",
            "0:\n",
            "LR: 0.001\n",
            "Loss - 0.67354 | Accuracy - 58.09%\n",
            "VLoss - 0.80803 | VAccuracy - 29.41%\n",
            "\n",
            "Validation accuracy: 29.44% | Validation loss: 0.8080\n",
            "Best model saved at: /content/drive/MyDrive/RespiraCheck/Cough Data/model_batch_size:16_lr:0.001_1740873121.3861074.pth\n",
            "âœ… Validation accuracy: 29.44% | Validation loss: 0.8080\n",
            "\n",
            "ðŸ”„ Epoch 3/20\n",
            "0:\n",
            "LR: 0.001\n",
            "Loss - 0.66645 | Accuracy - 60.04%\n",
            "VLoss - 0.67412 | VAccuracy - 56.75%\n",
            "\n",
            "Validation accuracy: 56.79% | Validation loss: 0.6741\n",
            "Best model saved at: /content/drive/MyDrive/RespiraCheck/Cough Data/model_batch_size:16_lr:0.001_1740873143.2397268.pth\n",
            "âœ… Validation accuracy: 56.79% | Validation loss: 0.6741\n",
            "\n",
            "ðŸ”„ Epoch 4/20\n",
            "0:\n",
            "LR: 0.001\n",
            "Loss - 0.61479 | Accuracy - 66.29%\n",
            "VLoss - 0.71965 | VAccuracy - 53.92%\n",
            "\n",
            "Validation accuracy: 54.01% | Validation loss: 0.7197\n",
            "Best model saved at: /content/drive/MyDrive/RespiraCheck/Cough Data/model_batch_size:16_lr:0.001_1740873165.3412445.pth\n",
            "âœ… Validation accuracy: 54.01% | Validation loss: 0.7197\n",
            "\n",
            "ðŸ”„ Epoch 5/20\n",
            "0:\n",
            "LR: 0.001\n",
            "Loss - 0.54394 | Accuracy - 73.04%\n",
            "VLoss - 0.66982 | VAccuracy - 69.17%\n",
            "\n",
            "Validation accuracy: 69.16% | Validation loss: 0.6698\n",
            "Best model saved at: /content/drive/MyDrive/RespiraCheck/Cough Data/model_batch_size:16_lr:0.001_1740873187.7733963.pth\n",
            "âœ… Validation accuracy: 69.16% | Validation loss: 0.6698\n",
            "\n",
            "ðŸ”„ Epoch 6/20\n",
            "0:\n",
            "LR: 0.001\n",
            "Loss - 0.43782 | Accuracy - 79.99%\n",
            "VLoss - 0.70021 | VAccuracy - 67.09%\n",
            "\n",
            "Validation accuracy: 67.07% | Validation loss: 0.7002\n",
            "Best model saved at: /content/drive/MyDrive/RespiraCheck/Cough Data/model_batch_size:16_lr:0.001_1740873210.2047477.pth\n",
            "âœ… Validation accuracy: 67.07% | Validation loss: 0.7002\n",
            "\n",
            "ðŸ”„ Epoch 7/20\n",
            "0:\n",
            "LR: 0.001\n",
            "Loss - 0.30534 | Accuracy - 86.98%\n",
            "VLoss - 0.80919 | VAccuracy - 72.69%\n",
            "\n",
            "Validation accuracy: 72.65% | Validation loss: 0.8092\n",
            "Best model saved at: /content/drive/MyDrive/RespiraCheck/Cough Data/model_batch_size:16_lr:0.001_1740873232.376771.pth\n",
            "âœ… Validation accuracy: 72.65% | Validation loss: 0.8092\n",
            "\n",
            "ðŸ”„ Epoch 8/20\n",
            "0:\n",
            "LR: 0.001\n",
            "Loss - 0.22843 | Accuracy - 90.75%\n",
            "VLoss - 0.97513 | VAccuracy - 67.24%\n",
            "\n",
            "Validation accuracy: 67.25% | Validation loss: 0.9751\n",
            "Best model saved at: /content/drive/MyDrive/RespiraCheck/Cough Data/model_batch_size:16_lr:0.001_1740873254.682099.pth\n",
            "âœ… Validation accuracy: 67.25% | Validation loss: 0.9751\n",
            "\n",
            "ðŸ”„ Epoch 9/20\n",
            "0:\n",
            "LR: 0.001\n",
            "Loss - 0.17908 | Accuracy - 92.78%\n",
            "VLoss - 1.05707 | VAccuracy - 67.58%\n",
            "\n",
            "Validation accuracy: 67.60% | Validation loss: 1.0571\n",
            "Best model saved at: /content/drive/MyDrive/RespiraCheck/Cough Data/model_batch_size:16_lr:0.001_1740873277.110227.pth\n",
            "âœ… Validation accuracy: 67.60% | Validation loss: 1.0571\n",
            "\n",
            "ðŸ”„ Epoch 10/20\n",
            "0:\n",
            "LR: 0.0005\n",
            "Loss - 0.08632 | Accuracy - 96.97%\n",
            "VLoss - 1.13432 | VAccuracy - 73.31%\n",
            "\n",
            "Validation accuracy: 73.34% | Validation loss: 1.1343\n",
            "Best model saved at: /content/drive/MyDrive/RespiraCheck/Cough Data/model_batch_size:16_lr:0.001_1740873299.471741.pth\n",
            "â¹ï¸ Early stopping triggered!\n",
            "\n",
            "ðŸŽ¯ Test accuracy: 66.95% ðŸš€ Best model saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audioprocessor = AudioProcessor()\n",
        "spectroprocessor = SpectrogramProcessor()\n",
        "datapipeline = DataPipeline(test_size=0.15, val_size=0.15,\n",
        "                            audio_processor=audioprocessor,\n",
        "                            spectrogram_processor=spectroprocessor,\n",
        "                            metadata_df=None,\n",
        "                            metadata_path=\"data/cough_data/metadata.csv\")\n",
        "train_loader, val_loader, test_loader = datapipeline.create_dataloaders(batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QwFKMeCfaaU",
        "outputId": "cd4de5a9-f9bc-476c-95d1-93442a9e72cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'AudioProcessor' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-31fbde46da3a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maudioprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mspectroprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpectrogramProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m datapipeline = DataPipeline(test_size=0.15, val_size=0.15, \n\u001b[1;32m      4\u001b[0m                             \u001b[0maudio_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maudioprocessor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                             \u001b[0mspectrogram_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspectroprocessor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'AudioProcessor' is not defined"
          ]
        }
      ]
    }
  ]
}